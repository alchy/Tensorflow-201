{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_show_digit(digit=0, train=True):\n",
    "    if train:\n",
    "        x = mnist.train.images[digit]\n",
    "        print('[i] number of bytes representing image: ', len(x), 'bytes')\n",
    "        print('[i] number of images: ', len(mnist.train.images))\n",
    "        print('[i] showing digit: ', digit)\n",
    "        x = x.reshape([28, 28])\n",
    "        plt.imshow(x, cmap='hot', interpolation='nearest')\n",
    "        plt.show()\n",
    "        print('hot vector: ', mnist.train.labels[digit])\n",
    "    else:\n",
    "        x = mnist.test.images[digit]\n",
    "        print('[i] number of bytes representing image: ', len(x), 'bytes')\n",
    "        print('[i] number of images: ', len(mnist.train.images))\n",
    "        print('[i] showing digit: ', digit)\n",
    "        x = x.reshape([28, 28])\n",
    "        plt.imshow(x, cmap='hot', interpolation='nearest')\n",
    "        plt.show()\n",
    "        print('hot vector: ', mnist.test.labels[digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of bytes representing image:  1 bytes\n",
      "[i] number of images:  55000\n",
      "[i] showing digit:  [43567]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d25375fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot vector:  [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "train_item = np.random.randint(len(mnist.train.images), size=1)\n",
    "mnist_show_digit(train_item, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hotvmax_pos_fast(hot_vector):\n",
    "    ''' with the max fn the algorithm proved to be 2x shorter \n",
    "        and 7x faster than the traditional approach '''\n",
    "    predition_max = max(hot_vector)\n",
    "    for pos in range(len(hot_vector)):\n",
    "        if hot_vector[pos] == predition_max:\n",
    "            return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        print('[i] creating layer, ', name, ' with ', n_inputs, ' neurons...')\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        \n",
    "        W = tf.Variable(tf.truncated_normal((n_inputs, n_neurons), \\\n",
    "            stddev=stddev), name='kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name='bias')\n",
    "        Z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # mnist array\n",
    "n_hidden1 = 300    # first hidden layer\n",
    "n_hidden2 = 100    # second hidden layer\n",
    "n_outputs = 10     # hot vector output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] creating layer,  hidden1  with  784  neurons...\n",
      "[i] creating layer,  hidden2  with  300  neurons...\n",
      "[i] creating layer,  output  with  100  neurons...\n",
      "[i] input Tensor is [ ? , 784 ]\n",
      "[i] where [instance_of_data, data_object]\n"
     ]
    }
   ],
   "source": [
    "with  tf.name_scope('input'):\n",
    "    input_x = tf.placeholder(tf.float32, shape=(None, n_inputs), name='x')\n",
    "\n",
    "with  tf.name_scope('target'):\n",
    "    target_y = tf.placeholder(tf.float32, [None, 10])\n",
    "    #target_y = tf.placeholder(tf.int8, shape=(None), name='y')\n",
    "\n",
    "with tf.name_scope('nn'):\n",
    "    hidden1 = neuron_layer(input_x, n_hidden1, 'hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, 'hidden2', activation=tf.nn.relu)\n",
    "    prediction = neuron_layer(hidden2, n_outputs, 'output')\n",
    "\n",
    "print('[i] input Tensor is [', input_x.get_shape()[0], ',', input_x.get_shape()[1], ']')\n",
    "print('[i] where [instance_of_data, data_object]')\n",
    "\n",
    "with tf.name_scope('cost'):\n",
    "    cost = tf.nn.l2_loss(prediction - target_y)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mnist_test():\n",
    "    correct_predictions = 0\n",
    "    for test_item in range(len(mnist.test.images)):\n",
    "        \n",
    "        predicted_label = sess.run(prediction, \n",
    "            feed_dict={input_x: mnist.test.images[test_item] [None, :]})\n",
    "\n",
    "        guess = get_hotvmax_pos_fast(predicted_label[0])\n",
    "        truth = get_hotvmax_pos_fast(mnist.test.labels[test_item])\n",
    "    \n",
    "        if guess == truth:\n",
    "            correct_predictions = correct_predictions + 1.0\n",
    "    \n",
    "    print('[i] total correct predictions is: ', correct_predictions)\n",
    "    print('[i] total data in test dataset is: ', len(mnist.test.images))\n",
    "    print('[i] success of the model is: ', \n",
    "        correct_predictions / len(mnist.test.images) * 100, '%')\n",
    "    print('[i] error of the model is: ',\n",
    "          100.0 - (correct_predictions / len(mnist.test.images) * 100, '%'))\n",
    "    print('[i] TEST finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_function_result_aggregated = 1000.0\n",
    "training_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] cost_function_result_aggregated:  90.9538618773\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    while cost_function_result_aggregated > 0.1: #0.1:\n",
    "        training_epoch = training_epoch + 1\n",
    "        \n",
    "        cost_function_result_aggregated = 0\n",
    "        for batch_epoch in range(0, 100):\n",
    "            \n",
    "            train_item = np.random.randint(len(mnist.train.images), size=1)\n",
    "            _, predicted_label, cost_function_result = \\\n",
    "                sess.run([optimizer, prediction, cost], \\\n",
    "                feed_dict = {input_x:  mnist.train.images[train_item], \\\n",
    "                             target_y: mnist.train.labels[train_item]})\n",
    "\n",
    "            cost_function_result_aggregated = \\\n",
    "                cost_function_result_aggregated + cost_function_result \n",
    "        \n",
    "        if training_epoch % 500 == 0:\n",
    "            print('[i] cost_function_result_aggregated: ', \\\n",
    "                  cost_function_result_aggregated)\n",
    "            \n",
    "    print('[i] final cost_function_result_aggregated: ', \\\n",
    "          cost_function_result_aggregated)\n",
    "    print('[i] TRAINING finished...')\n",
    "    mnist_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
