{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_show_digit(digit=0, train=True):\n",
    "    if train:\n",
    "        x = mnist.train.images[digit]\n",
    "        print('[i] number of bytes representing image: ', len(x), 'bytes')\n",
    "        print('[i] number of images: ', len(mnist.train.images))\n",
    "        print('[i] showing digit: ', digit)\n",
    "        x = x.reshape([28, 28])\n",
    "        plt.imshow(x, cmap='hot', interpolation='nearest')\n",
    "        plt.show()\n",
    "        print('hot vector: ', mnist.train.labels[digit])\n",
    "    else:\n",
    "        x = mnist.test.images[digit]\n",
    "        print('[i] number of bytes representing image: ', len(x), 'bytes')\n",
    "        print('[i] number of images: ', len(mnist.train.images))\n",
    "        print('[i] showing digit: ', digit)\n",
    "        x = x.reshape([28, 28])\n",
    "        plt.imshow(x, cmap='hot', interpolation='nearest')\n",
    "        plt.show()\n",
    "        print('hot vector: ', mnist.test.labels[digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of bytes representing image:  1 bytes\n",
      "[i] number of images:  55000\n",
      "[i] showing digit:  [50090]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/FJRhl8q6v8BuQ8UcMyl1cgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2ff0b3e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot vector:  [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "train_item = np.random.randint(len(mnist.train.images), size=1)\n",
    "mnist_show_digit(train_item, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hotvmax_pos_fast(hot_vector):\n",
    "    ''' with the max fn the algorithm proved to be 2x shorter \n",
    "        and 7x faster than the traditional approach '''\n",
    "    predition_max = max(hot_vector)\n",
    "    for pos in range(len(hot_vector)):\n",
    "        if hot_vector[pos] == predition_max:\n",
    "            return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        print('[i] creating layer, ', name, ' with ', n_inputs, ' neurons...')\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        \n",
    "        W = tf.Variable(tf.truncated_normal((n_inputs, n_neurons), \\\n",
    "            stddev=stddev), name='kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name='bias')\n",
    "        Z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # mnist array\n",
    "n_hidden1 = 300    # first hidden layer\n",
    "n_hidden2 = 100    # second hidden layer\n",
    "n_outputs = 10     # hot vector output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] creating layer,  hidden1  with  784  neurons...\n",
      "[i] creating layer,  hidden2  with  300  neurons...\n",
      "[i] creating layer,  output  with  100  neurons...\n",
      "[i] input Tensor is [ ? , 784 ]\n",
      "[i] where [instance_of_data, data_object]\n"
     ]
    }
   ],
   "source": [
    "with  tf.name_scope('input'):\n",
    "    input_x = tf.placeholder(tf.float32, shape=(None, n_inputs), name='x')\n",
    "\n",
    "with  tf.name_scope('target'):\n",
    "    target_y = tf.placeholder(tf.float32, [None, 10])\n",
    "    #target_y = tf.placeholder(tf.int8, shape=(None), name='y')\n",
    "\n",
    "with tf.name_scope('nn'):\n",
    "    hidden1 = neuron_layer(input_x, n_hidden1, 'hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, 'hidden2', activation=tf.nn.relu)\n",
    "    prediction = neuron_layer(hidden2, n_outputs, 'output')\n",
    "\n",
    "print('[i] input Tensor is [', input_x.get_shape()[0], ',', input_x.get_shape()[1], ']')\n",
    "print('[i] where [instance_of_data, data_object]')\n",
    "\n",
    "with tf.name_scope('cost'):\n",
    "    cost = tf.nn.l2_loss(prediction - target_y)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mnist_test():\n",
    "    correct_predictions = 0\n",
    "    for test_item in range(len(mnist.test.images)):\n",
    "        \n",
    "        predicted_label = sess.run(prediction, \n",
    "            feed_dict={input_x: mnist.test.images[test_item] [None, :]})\n",
    "\n",
    "        guess = get_hotvmax_pos_fast(predicted_label[0])\n",
    "        truth = get_hotvmax_pos_fast(mnist.test.labels[test_item])\n",
    "    \n",
    "        if guess == truth:\n",
    "            correct_predictions = correct_predictions + 1.0\n",
    "    \n",
    "    print('[i] total correct predictions is: ', correct_predictions)\n",
    "    print('[i] total data in test dataset is: ', len(mnist.test.images))\n",
    "    print('[i] success of the model is: ', \n",
    "        correct_predictions / len(mnist.test.images) * 100, '%')\n",
    "    print('[i] error of the model is: ',\n",
    "          100.0 - (correct_predictions / len(mnist.test.images)) * 100, '%')\n",
    "    print('[i] TEST finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_function_result_aggregated = 1000.0\n",
    "training_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] cost_function_result_aggregated:  96.5342834741\n",
      "[i] cost_function_result_aggregated:  4.49894461448\n",
      "[i] cost_function_result_aggregated:  1.73838173742\n",
      "[i] cost_function_result_aggregated:  3.368030029\n",
      "[i] cost_function_result_aggregated:  3.19761844028\n",
      "[i] cost_function_result_aggregated:  1.90343761235\n",
      "[i] cost_function_result_aggregated:  1.98766351628\n",
      "[i] cost_function_result_aggregated:  0.86762309225\n",
      "[i] cost_function_result_aggregated:  1.56331591361\n",
      "[i] cost_function_result_aggregated:  1.436716418\n",
      "[i] cost_function_result_aggregated:  1.05380109375\n",
      "[i] cost_function_result_aggregated:  1.17770652781\n",
      "[i] cost_function_result_aggregated:  0.906995932281\n",
      "[i] cost_function_result_aggregated:  0.660714119505\n",
      "[i] cost_function_result_aggregated:  0.569099569188\n",
      "[i] cost_function_result_aggregated:  0.905075157481\n",
      "[i] cost_function_result_aggregated:  0.804916857442\n",
      "[i] cost_function_result_aggregated:  1.05706421671\n",
      "[i] cost_function_result_aggregated:  0.908453519607\n",
      "[i] cost_function_result_aggregated:  1.30700018099\n",
      "[i] cost_function_result_aggregated:  0.32758001459\n",
      "[i] cost_function_result_aggregated:  0.948841522742\n",
      "[i] cost_function_result_aggregated:  0.485669039598\n",
      "[i] cost_function_result_aggregated:  0.934218467091\n",
      "[i] cost_function_result_aggregated:  0.492762941967\n",
      "[i] cost_function_result_aggregated:  0.725012811491\n",
      "[i] cost_function_result_aggregated:  0.45808631619\n",
      "[i] cost_function_result_aggregated:  0.294080411868\n",
      "[i] cost_function_result_aggregated:  0.419622201805\n",
      "[i] cost_function_result_aggregated:  0.721615410632\n",
      "[i] cost_function_result_aggregated:  0.22391916624\n",
      "[i] cost_function_result_aggregated:  0.427521704192\n",
      "[i] cost_function_result_aggregated:  0.288787592322\n",
      "[i] cost_function_result_aggregated:  0.675330690736\n",
      "[i] cost_function_result_aggregated:  0.35819077107\n",
      "[i] cost_function_result_aggregated:  0.191624039124\n",
      "[i] cost_function_result_aggregated:  0.319854811405\n",
      "[i] cost_function_result_aggregated:  0.211367631854\n",
      "[i] cost_function_result_aggregated:  0.196193058964\n",
      "[i] cost_function_result_aggregated:  0.129710028195\n",
      "[i] cost_function_result_aggregated:  0.232234309561\n",
      "[i] final cost_function_result_aggregated:  0.0973408131567\n",
      "[i] TRAINING finished...\n",
      "[i] total correct predictions is:  9811.0\n",
      "[i] total data in test dataset is:  10000\n",
      "[i] success of the model is:  98.11 %\n",
      "[i] error of the model is:  1.8900000000000006 %\n",
      "[i] TEST finished...\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    while cost_function_result_aggregated > 0.1: #0.1:\n",
    "        training_epoch = training_epoch + 1\n",
    "        \n",
    "        cost_function_result_aggregated = 0\n",
    "        for batch_epoch in range(0, 100):\n",
    "            \n",
    "            train_item = np.random.randint(len(mnist.train.images), size=1)\n",
    "            _, predicted_label, cost_function_result = \\\n",
    "                sess.run([optimizer, prediction, cost], \\\n",
    "                feed_dict = {input_x:  mnist.train.images[train_item], \\\n",
    "                             target_y: mnist.train.labels[train_item]})\n",
    "\n",
    "            cost_function_result_aggregated = \\\n",
    "                cost_function_result_aggregated + cost_function_result \n",
    "        \n",
    "        if training_epoch % 500 == 0:\n",
    "            print('[i] cost_function_result_aggregated: ', \\\n",
    "                  cost_function_result_aggregated)\n",
    "            \n",
    "    print('[i] final cost_function_result_aggregated: ', \\\n",
    "          cost_function_result_aggregated)\n",
    "    print('[i] TRAINING finished...')\n",
    "    mnist_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
